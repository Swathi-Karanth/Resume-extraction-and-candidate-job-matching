{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNO8N5eTb4eQ5SWpmmj4UFS"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install pdfminer\n",
        "!pip install PyPDF2\n",
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94dyYbK2fA0Z",
        "outputId": "2563a993-716f-4b75-df6a-651be9596083"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.33.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.17.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.3.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<2023.9.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.17.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: pdfminer in /usr/local/lib/python3.10/dist-packages (20191125)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.10/dist-packages (from pdfminer) (3.19.0)\n",
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.15.2+cu118)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "import pdfminer\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "from pdfminer.pdfparser import PDFParser\n",
        "from pdfminer.pdfdocument import PDFDocument\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "from pdfminer.pdfpage import PDFPage\n",
        "from pdfminer.layout import LAParams, LTTextBox\n",
        "from io import StringIO\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "GYHPtDoHgUJh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        num_pages = len(pdf_reader.pages)\n",
        "\n",
        "        for page_num in range(num_pages):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Define the function to extract key details from a PDF resume\n",
        "def extract_resume_details(pdf_file):\n",
        "    \"\"\"Extracts key details from a PDF resume.\n",
        "\n",
        "    Args:\n",
        "        pdf_file: The path to the PDF resume file.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the extracted key details, including:\n",
        "            category: The job role of the candidate.\n",
        "            skills: A list of the candidate's skills.\n",
        "            education: A list of the candidate's educational qualifications.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract the text from the PDF file\n",
        "    with open(pdf_file, \"rb\") as f:\n",
        "        text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "    # Parse the text to extract the key details\n",
        "    role = text.split(\"\\n\")[0]\n",
        "    skills = r'Skills((?:(?!Education|Education and Training|Experience|Accomplishments|Work History|ProfessionalExperience|Languages|Additional Information|Highlights|Interests).)+)'\n",
        "    skills_match = re.search(skills, text, re.DOTALL | re.IGNORECASE)\n",
        "    if skills_match:\n",
        "        skills = skills_match.group(1).strip()\n",
        "    else:\n",
        "        skills = None\n",
        "    education = r'Education((?:(?!Skills|Experience|Accomplishments|Work History|ProfessionalExperience|Languages|Additional Information|Highlights|Interests).)+)'\n",
        "    education_match = re.search(education, text, re.DOTALL | re.IGNORECASE)\n",
        "    if education_match:\n",
        "        education = education_match.group(1).strip()\n",
        "    else:\n",
        "        education = None\n",
        "    # Return the extracted key details\n",
        "    return {\n",
        "        \"file_path\" : pdf_file,\n",
        "        \"role\": role,\n",
        "        \"skills\": skills,\n",
        "        \"education\": education,\n",
        "    }"
      ],
      "metadata": {
        "id": "NIMlw6lLgbAe"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to fetch job descriptions from the Hugging Face dataset\n",
        "def fetch_job_descriptions():\n",
        "    \"\"\"Fetches job descriptions from the Hugging Face dataset.\n",
        "\n",
        "    Returns:\n",
        "        A list of job descriptions.\n",
        "    \"\"\"\n",
        "\n",
        "    # Import the Hugging Face datasets library\n",
        "    import datasets\n",
        "\n",
        "    # Load the Job Descriptions dataset from Hugging Face\n",
        "    dataset = datasets.load_dataset(\"jacob-hugging-face/job-descriptions\")\n",
        "\n",
        "    # Select a random sample of 15 job descriptions\n",
        "    job_descriptions = random.choices(dataset[\"train\"][\"job_description\"], k=15)\n",
        "\n",
        "    # Return the job descriptions\n",
        "    return job_descriptions"
      ],
      "metadata": {
        "id": "uYkQ5KSbgu9C"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to calculate the cosine similarity between two embeddings\n",
        "def calculate_cosine_similarity(embedding1, embedding2):\n",
        "    \"\"\"Calculates the cosine similarity between two embeddings.\n",
        "\n",
        "    Args:\n",
        "        embedding1: The first embedding.\n",
        "        embedding2: The second embedding.\n",
        "\n",
        "    Returns:\n",
        "        The cosine similarity between the two embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    embedding1 = np.array(embedding1).reshape(1, -1)\n",
        "    embedding2 = np.array(embedding2).reshape(1, -1)\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    similarity = cosine_similarity(embedding1, embedding2)[0][0]\n",
        "\n",
        "    # Return the cosine similarity\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "PiVpKg-Vg0cE"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to match candidate resumes to job descriptions based on skills and education\n",
        "def match_candidates_to_jobs(candidates, job_descriptions):\n",
        "    \"\"\"Matches candidate resumes to job descriptions based on skills and education.\n",
        "\n",
        "    Args:\n",
        "        candidates: A list of candidate resumes.\n",
        "        job_descriptions: A list of job descriptions.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary mapping each job description to a list of the top 5 matching candidate resumes.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a dictionary to store the matching results\n",
        "    matching_results = {}\n",
        "\n",
        "    # Iterate over the job descriptions\n",
        "    for job_description in job_descriptions:\n",
        "\n",
        "        # Get the job description embedding\n",
        "        job_description_embedding = get_embedding(job_description)\n",
        "\n",
        "        # Create a list to store the matching candidates\n",
        "        matching_candidates = []\n",
        "\n",
        "        # Iterate over the candidate resumes\n",
        "        for candidate in candidates:\n",
        "            print(candidate)\n",
        "            candidate_info = str(candidate[\"role\"]) +\" \"+ str(candidate[\"skills\"]) +\" \"+ str(candidate[\"education\"])\n",
        "            # Get the candidate resume embedding\n",
        "            candidate_embedding = get_embedding(candidate_info)\n",
        "\n",
        "            # Calculate the cosine similarity between the job description and the candidate resume\n",
        "            similarity = calculate_cosine_similarity(job_description_embedding, candidate_embedding)\n",
        "\n",
        "            # Add the candidate to the matching candidates list if the similarity is greater than a certain threshold\n",
        "            if similarity > 0.3:\n",
        "                matching_candidates.append((candidate, similarity))\n",
        "\n",
        "        # Sort the matching candidates list by similarity\n",
        "        matching_candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Add the top 5 matching candidates to the matching results dictionary\n",
        "        matching_results[job_description] = matching_candidates[:5]\n",
        "\n",
        "    # Return the matching results dictionary\n",
        "    return matching_results\n"
      ],
      "metadata": {
        "id": "4T7qxtcRg2B5"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to get the embedding of a text sequence using a pre-trained model\n",
        "def get_embedding(text_sequence):\n",
        "    \"\"\"Gets the embedding of a text sequence using a pre-trained model.\n",
        "\n",
        "    Args:\n",
        "        text_sequence: The text sequence to get the embedding.\n",
        "\n",
        "    Returns:\n",
        "        The embedding of the text sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the pre-trained DistilBERT tokenizer and model\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "    model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "    # Tokenize the text sequence\n",
        "    tokenized_text = tokenizer(text_sequence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Get the embedding of the tokenized text\n",
        "    with torch.no_grad():\n",
        "        embedding = torch.mean(model(**tokenized_text).last_hidden_state, dim=1)\n",
        "\n",
        "    # Return the embedding\n",
        "    return embedding\n"
      ],
      "metadata": {
        "id": "kbp33mEOg8kH"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMbuVabpQtMQ"
      },
      "outputs": [],
      "source": [
        "# Extract the key details from the PDF resumes\n",
        "extracted_data = open('extracted_data.csv', 'w', newline='')\n",
        "csvwriter = csv.writer(extracted_data)\n",
        "\n",
        "csvwriter.writerow([\"category\", \"file_path\", \"role\", \"skills\", \"education\"])\n",
        "for root, dirs, files in os.walk(\"data\"):\n",
        "    for file in files:\n",
        "        pdf_file = os.path.join(root, file)\n",
        "        candidate_details = {}\n",
        "        candidate_details[\"category\"] = dirs\n",
        "        candidate_details.update(extract_resume_details(pdf_file))\n",
        "        csvwriter.writerow(candidate_details.values())\n",
        "\n",
        "extracted_data.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the job descriptions from the Hugging Face dataset\n",
        "job_descriptions = fetch_job_descriptions()\n",
        "\n",
        "candidates = pd.read_csv('extracted_data.csv').to_dict(orient='records')\n",
        "# Match the candidate resumes to the job descriptions\n",
        "matching_results = match_candidates_to_jobs(candidates, job_descriptions)\n",
        "\n",
        "# Write the matching results to a CSV file\n",
        "with open(\"matching_results.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Job description\", \"Matching candidates\"])\n",
        "    for job_description, matching_candidates in matching_results.items():\n",
        "        candidates_string = \",\".join([candidate[0][\"category\"] for candidate in matching_candidates])\n",
        "        writer.writerow([job_description, candidates_string])"
      ],
      "metadata": {
        "id": "Mrtlx4Iy8Jz1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}