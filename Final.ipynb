{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8MjGq1NEtXKkrT23gKtsP"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2\n",
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "94dyYbK2fA0Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import DistilBertTokenizerFast, DistilBertModel\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import PyPDF2"
      ],
      "metadata": {
        "id": "GYHPtDoHgUJh"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, 'rb') as pdf_file:\n",
        "        pdf_reader = PyPDF2.PdfReader(pdf_file)\n",
        "        num_pages = len(pdf_reader.pages)\n",
        "\n",
        "        for page_num in range(num_pages):\n",
        "            page = pdf_reader.pages[page_num]\n",
        "            text += page.extract_text()\n",
        "\n",
        "    return text\n",
        "\n",
        "# Define the function to extract key details from a PDF resume\n",
        "def extract_resume_details(pdf_file):\n",
        "    \"\"\"Extracts key details from a PDF resume.\n",
        "\n",
        "    Args:\n",
        "        pdf_file: The path to the PDF resume file.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary containing the extracted key details, including:\n",
        "            category: The job role of the candidate.\n",
        "            skills: A list of the candidate's skills.\n",
        "            education: A list of the candidate's educational qualifications.\n",
        "    \"\"\"\n",
        "\n",
        "    # Extract the text from the PDF file\n",
        "    with open(pdf_file, \"rb\") as f:\n",
        "        text = extract_text_from_pdf(pdf_file)\n",
        "\n",
        "    # Parse the text to extract the key details\n",
        "    role = text.split(\"\\n\")[0]\n",
        "    skills = r'Skills((?:(?!Education|Education and Training|Experience|Accomplishments|Work History|ProfessionalExperience|Languages|Additional Information|Highlights|Interests).)+)'\n",
        "    skills_match = re.search(skills, text, re.DOTALL | re.IGNORECASE)\n",
        "    if skills_match:\n",
        "        skills = skills_match.group(1).strip()\n",
        "    else:\n",
        "        skills = None\n",
        "    education = r'Education((?:(?!Skills|Experience|Accomplishments|Work History|ProfessionalExperience|Languages|Additional Information|Highlights|Interests).)+)'\n",
        "    education_match = re.search(education, text, re.DOTALL | re.IGNORECASE)\n",
        "    if education_match:\n",
        "        education = education_match.group(1).strip()\n",
        "    else:\n",
        "        education = None\n",
        "    # Return the extracted key details\n",
        "    return {\n",
        "        \"file_path\" : pdf_file,\n",
        "        \"role\": role,\n",
        "        \"skills\": skills,\n",
        "        \"education\": education,\n",
        "    }"
      ],
      "metadata": {
        "id": "NIMlw6lLgbAe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to fetch job descriptions from the Hugging Face dataset\n",
        "def fetch_job_descriptions():\n",
        "    \"\"\"Fetches job descriptions from the Hugging Face dataset.\n",
        "\n",
        "    Returns:\n",
        "        A list of job descriptions.\n",
        "    \"\"\"\n",
        "\n",
        "    # Import the Hugging Face datasets library\n",
        "    import datasets\n",
        "\n",
        "    # Load the Job Descriptions dataset from Hugging Face\n",
        "    dataset = datasets.load_dataset(\"jacob-hugging-face/job-descriptions\")\n",
        "\n",
        "    # Select a random sample of 15 job descriptions\n",
        "    job_descriptions = random.choices(dataset[\"train\"][\"job_description\"], k=15)\n",
        "\n",
        "    # Return the job descriptions\n",
        "    return job_descriptions"
      ],
      "metadata": {
        "id": "uYkQ5KSbgu9C"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to calculate the cosine similarity between two embeddings\n",
        "def calculate_cosine_similarity(embedding1, embedding2):\n",
        "    \"\"\"Calculates the cosine similarity between two embeddings.\n",
        "\n",
        "    Args:\n",
        "        embedding1: The first embedding.\n",
        "        embedding2: The second embedding.\n",
        "\n",
        "    Returns:\n",
        "        The cosine similarity between the two embeddings.\n",
        "    \"\"\"\n",
        "\n",
        "    embedding1 = np.array(embedding1).reshape(1, -1)\n",
        "    embedding2 = np.array(embedding2).reshape(1, -1)\n",
        "\n",
        "    # Calculate the cosine similarity\n",
        "    similarity = cosine_similarity(embedding1, embedding2)[0][0]\n",
        "\n",
        "    # Return the cosine similarity\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "PiVpKg-Vg0cE"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to match candidate resumes to job descriptions based on skills and education\n",
        "def match_candidates_to_jobs(candidates, job_descriptions):\n",
        "    \"\"\"Matches candidate resumes to job descriptions based on skills and education.\n",
        "\n",
        "    Args:\n",
        "        candidates: A list of candidate resumes.\n",
        "        job_descriptions: A list of job descriptions.\n",
        "\n",
        "    Returns:\n",
        "        A dictionary mapping each job description to a list of the top 5 matching candidate resumes.\n",
        "    \"\"\"\n",
        "\n",
        "    # Create a dictionary to store the matching results\n",
        "    matching_results = {}\n",
        "\n",
        "    # Iterate over the job descriptions\n",
        "    for job_description in job_descriptions:\n",
        "\n",
        "        # Get the job description embedding\n",
        "        job_description_embedding = get_embedding(job_description)\n",
        "\n",
        "        # Create a list to store the matching candidates\n",
        "        matching_candidates = []\n",
        "\n",
        "        # Iterate over the candidate resumes\n",
        "        for candidate in candidates:\n",
        "            print(candidate)\n",
        "            candidate_info = str(candidate[\"role\"]) +\" \"+ str(candidate[\"skills\"]) +\" \"+ str(candidate[\"education\"])\n",
        "            # Get the candidate resume embedding\n",
        "            candidate_embedding = get_embedding(candidate_info)\n",
        "\n",
        "            # Calculate the cosine similarity between the job description and the candidate resume\n",
        "            similarity = calculate_cosine_similarity(job_description_embedding, candidate_embedding)\n",
        "\n",
        "            # Add the candidate to the matching candidates list if the similarity is greater than a certain threshold\n",
        "            if similarity > 0.3:\n",
        "                matching_candidates.append((candidate, similarity))\n",
        "\n",
        "        # Sort the matching candidates list by similarity\n",
        "        matching_candidates.sort(key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # Add the top 5 matching candidates to the matching results dictionary\n",
        "        matching_results[job_description] = matching_candidates[:5]\n",
        "\n",
        "    # Return the matching results dictionary\n",
        "    return matching_results\n"
      ],
      "metadata": {
        "id": "4T7qxtcRg2B5"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the function to get the embedding of a text sequence using a pre-trained model\n",
        "def get_embedding(text_sequence):\n",
        "    \"\"\"Gets the embedding of a text sequence using a pre-trained model.\n",
        "\n",
        "    Args:\n",
        "        text_sequence: The text sequence to get the embedding.\n",
        "\n",
        "    Returns:\n",
        "        The embedding of the text sequence.\n",
        "    \"\"\"\n",
        "\n",
        "    # Load the pre-trained DistilBERT tokenizer and model\n",
        "    tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
        "    model = DistilBertModel.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "    # Tokenize the text sequence\n",
        "    tokenized_text = tokenizer(text_sequence, return_tensors=\"pt\", padding=True, truncation=True)\n",
        "\n",
        "    # Get the embedding of the tokenized text\n",
        "    with torch.no_grad():\n",
        "        embedding = torch.mean(model(**tokenized_text).last_hidden_state, dim=1)\n",
        "\n",
        "    # Return the embedding\n",
        "    return embedding\n"
      ],
      "metadata": {
        "id": "kbp33mEOg8kH"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IMbuVabpQtMQ"
      },
      "outputs": [],
      "source": [
        "# Extract the key details from the PDF resumes\n",
        "extracted_data = open('extracted_data.csv', 'w', newline='')\n",
        "csvwriter = csv.writer(extracted_data)\n",
        "\n",
        "csvwriter.writerow([\"category\", \"file_path\", \"role\", \"skills\", \"education\"])\n",
        "pdf_folder_path = \"data\"      # replace this with the name of the folder containing subfolders (like, ACCOUNTANT, etc. while eexecuting the code.)\n",
        "for root, dirs, files in os.walk(pdf_folder_path):\n",
        "    for file in files:\n",
        "        pdf_file = os.path.join(root, file)\n",
        "        candidate_details = {}\n",
        "        candidate_details[\"category\"] = pdf_file.split(\"/\")[-2]\n",
        "        candidate_details.update(extract_resume_details(pdf_file))\n",
        "        csvwriter.writerow(candidate_details.values())\n",
        "\n",
        "extracted_data.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fetch the job descriptions from the Hugging Face dataset\n",
        "job_descriptions = fetch_job_descriptions()\n",
        "\n",
        "candidates = pd.read_csv('extracted_data.csv').to_dict(orient='records')\n",
        "# Match the candidate resumes to the job descriptions\n",
        "matching_results = match_candidates_to_jobs(candidates, job_descriptions)\n",
        "\n",
        "# Write the matching results to a CSV file\n",
        "with open(\"matching_results.csv\", \"w\", newline=\"\") as f:\n",
        "    writer = csv.writer(f)\n",
        "    writer.writerow([\"Job description\", \"Matching candidates\"])\n",
        "    for job_description, matching_candidates in matching_results.items():\n",
        "        candidates_string = \",\".join([candidate[0][\"category\"] for candidate in matching_candidates])\n",
        "        writer.writerow([job_description, candidates_string])"
      ],
      "metadata": {
        "id": "Mrtlx4Iy8Jz1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}